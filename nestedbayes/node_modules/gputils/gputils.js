/*
 This file defines cache with gaussian process interpolation, suitable for real-valued functions.
 cache is to be called as an external primitive (i.e. gpcache.cache(f)), but passed a WebPPL function.
 */
"use strict";

var matrix = require('sylvester')
var Vector = matrix.Vector


//This form caches a function whose single arg is an array of reals.
function GPCache(f, varianceThresh) {
  var varianceThresh = varianceThresh || 1.0
  var trainingArgs = [];
  var trainingVals = [];
  var kernel = Kernels.kernelBuilder(Kernels.constant(1),
                                     Kernels.linear(1),
                                     Kernels.gaussianNoise(1),
                                     Kernels.squaredExponential(1,-1));
  var gp = GaussianProcess(kernel);
  
  //create the cached function:
  var cf = function(s,k,a,realArgsArray) {
//    var otherArgs = Array.prototype.slice.call(arguments, 4);
    var args = realArgsArray
    var argsV = Vector.create(args)
    
    //estimate f(args) based on existing data:
    if(trainingArgs.length > 0) {
      console.log("prediction for args "+args+"...")
      var predicted = gp.evaluate([argsV])
      console.log(predicted)
    } else {
      var predicted = null
    }
    
    
    //if variance of estimate is too high evaluate f(args), otherwise use estimate:
    if(predicted == null || predicted.sigma.e(1,1) > varianceThresh) {
      console.log("computing new val for args "+args)
      trainingArgs.push(argsV)
      var newk = function(s,r) {
        trainingVals.push(r)
        //re-train GP:
        console.log("  re-training GP...")
        gp.train(trainingArgs, $M(trainingVals))
        console.log("  trained.")
        k(s,r);
      };
      f(s,newk,a,args);
    } else {
      console.log("using prediction "+ predicted.mu.e(1,1) +" for args "+args)
      k(s,predicted.mu.e(1,1))
    }
  }
  
  return cf;
}


//this form caches a function whose first arg is an array of reals, and other args are whatever. interpolates for first arg.
function mixedCache(f,vt) {
  var c = {};
  var cf = function(s,k,a,RealArgsArray,otherArgsHere) {
    var otherArgs = Array.prototype.slice.call(arguments, 4);
    var GPfn;
    
    var stringedArgs = JSON.stringify(otherArgs);
    if (stringedArgs in c) {
      GPfn = c[stringedArgs]
    } else {
      GPfn = GPCache(function(s,k,a,RealArgsArray){
                     return f.apply(this, [s,k,a,RealArgsArray].concat(otherArgs))
                     },vt)
      c[stringedArgs] = GPfn
    }
    GPfn(s,k,a,RealArgsArray)
  }
  
  return cf
}


/////// The below code was adapted from: https://github.com/scotthellman/gaussianprocess_js

var Kernels = function(){
  
  function constant(x,y){
    return 1;
  }
  
  function linear(x,y){
    return x.dot(y);
  }
  
  function gaussianNoise(x,y){
    if(x.eql(y)){
      return 1;
    }
    return 0;
  }
  
  function squaredExponential(x,y,l){
    var diff = x.subtract(y);
    diff = diff.dot(diff);
    return Math.exp(-1 * (diff/(l*l)));
  }
  
  //matern with nu=3/2
  function matern(x,y,l){
    var diff = x.subtract(y);
    diff = diff.dot(diff);
    diff = Math.sqrt(diff);
    var result = (1 + Math.sqrt(3) * diff / l);
    result *= Math.exp(-1 * Math.sqrt(3) * diff/l);
    return result;
  }
  
  function kernelBuilder(){
    var functions = arguments;
    return{
      kernel : function(x,y){
        var result = 0;
        for(var i = 0; i < functions.length; i++){
          result += functions[i].kernel(x,y);
        }
        return result;
      },
      gradient : function(x,y,func,parameter){
        return functions[func].gradients[parameter](x,y);
      },
      
      functions : functions
    }
  }
  
  return {
    constant : function(theta) {
      var parameters = [theta];
      return {
        kernel : function(x,y){return parameters[0] * constant(x,y);},
        gradients : [function(x,y){return constant(x,y);}],
        parameters : parameters
      }
    },
    
    linear : function(theta) {
      var parameters = [theta];
      return{
        kernel : function(x,y){return parameters[0] * linear(x,y);},
        gradients : [function(x,y){return linear(x,y);}],
        parameters : parameters
      }
    },
    gaussianNoise : function(theta) {
      var parameters = [theta];
      return{
        kernel : function(x,y){return parameters[0] * gaussianNoise(x,y);},
        gradients : [], //function of our prior knowledge?
        // gradients : [function(x,y){return gaussianNoise(x,y);}],
        parameters : parameters
      }
    },
    squaredExponential : function(theta,l) {
      var parameters = [theta,l];
      return{
        kernel : function(x,y){return parameters[0] * squaredExponential(x,y,parameters[1]);},
        gradients : [function(x,y){return squaredExponential(x,y,parameters[1])},
                     function(x,y){
                     var diff = x.subtract(y);
                     diff = diff.dot(diff);
                     var result = -2 * diff * parameters[0] * squaredExponential(x,y,parameters[1])/Math.pow(parameters[1],3)
                     return result;
                     }],
        parameters : parameters
      }
    },
    matern : function(theta,l) {
      var parameters = [theta,l];
      return{
        kernel : function(x,y){return parameters[0] * matern(x,y,parameters[1]);},
        gradients : [function(x,y){return matern(x,y,parameters[1])},
                     function(x,y){
                     var diff = x.subtract(y);
                     diff = diff.dot(diff);
                     diff = Math.sqrt(diff);
                     var result = 3 * parameters[0] * diff * diff;
                     result *= Math.exp(-Math.sqrt(3) * diff / parameters[1]);
                     result /= Math.pow(parameters[1],3);
                     return result;
                     }],
        parameters : parameters
      }
    },
    kernelBuilder : kernelBuilder
  }
}();

function GaussianProcess(kernel){
  
  var C,Cinv,training_data,training_labels;
  
  function train(data,labels) {
    training_data = data
    training_labels = labels
//    console.log("    gradient descent...")
//    gradientDescent(training_labels,training_data,0.1,0.005,20)
    console.log("    Cinv...")
    C = applyKernel(training_data,training_data,kernel);
    Cinv = C.inv();
  }
  
  function evaluate(testing_data){
    //build covariance matrix components
//    var C = applyKernel(training_data,training_data,kernel);
    var k = applyKernel(training_data,testing_data,kernel);
//    var Cinv = C.inv();
    var c = applyKernel(testing_data,testing_data,kernel);
    
    //condition
    var mu = k.transpose().x(Cinv.x(training_labels));
    var sigma = c.subtract(k.transpose().x(Cinv.x(k)));
    
    return{
    mu:mu,
    sigma:sigma
    }
  }
  
  function gradientDescent(y,X,cutoff,gamma,max_iterations){
    var delta = null;
    var max_delta = 10;
    var current = [];
    
    //get our gradient indexing figured out
    var function_indices = [];
    var parameter_indices = [];
    for(var i = 0; i < kernel.functions.length; i++){
      for(var j = 0; j < kernel.functions[i].gradients.length; j++){
        function_indices.push(i);
        parameter_indices.push(j);
        current.push(kernel.functions[i].parameters[j])
      }
    }
    
    var iterations = 0;
    while(max_delta > cutoff && iterations < max_iterations){
      max_delta = 0;
      iterations++;
      var K = applyKernel(X,X,kernel);
      var K_inv = K.inv();
      for(var i = 0; i < current.length; i++){
        delta = d_likelihood_slow(y,X,K,K_inv,kernel,function_indices[i],parameter_indices[i]);
        max_delta = Math.max(Math.abs(delta),max_delta);
        var old = current[i];
        current[i] -= delta * gamma;
      }
      for(var i = 0; i < current.length; i++){
        kernel.functions[function_indices[i]].parameters[parameter_indices[i]] = current[i];
      }
    }
  }
  
  //TODO: doesn't work
  function d_likelihood(y,X,K,K_inv,kernel,function_index,param_index){
    var result = K_inv.x(y);
    result = result.x(result.transpose());
    result = result.subtract(K_inv);
    result = result.x(applyKernelGradient(X,X,kernel,function_index,param_index));
    return 0.5 * result.trace();
  }
  
  function d_likelihood_slow(y,X,K,K_inv,kernel,function_index,param_index){
    var d_K = applyKernelGradient(X,X,kernel,function_index,param_index);
    var result = y.transpose().x(K_inv).x(d_K).x(K_inv).x(y).e(0,0);
    var penalty = K_inv.x(d_K).trace();
    result = 0.5 * (result - penalty);
    return result
  }
  
  function applyKernel(X,Y,kernel){
    var result_array = []
    for(var i = 0; i < X.length; i++){
      result_array.push([]);
      for(var j = 0; j < Y.length; j++){
        result_array[i].push(kernel.kernel(X[i],Y[j]));
      }
    }
    return $M(result_array);
  }
  
  function applyKernelGradient(X,Y,kernel,function_index,param_index){
    var result_array = []
    for(var i = 0; i < X.length; i++){
      result_array.push([]);
      for(var j = 0; j < Y.length; j++){
        result_array[i].push(kernel.gradient(X[i],Y[j],function_index,param_index));
      }
    }
    return $M(result_array);
  }
  
  return{
		evaluate:evaluate,
    train:train,
//		gradientDescent:gradientDescent,
		kernel:kernel
  }
}

function wrapScalarsAsVectors(xs){
  result = [];
  for(var i = 0; i < xs.length; i++){
    result.push(Vector.create([xs[i]]));
  }
  return result;
}

////////////////////////
module.exports = {
cache: mixedCache
}
